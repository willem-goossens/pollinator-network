---
title: "PlantNet URL"
author: "Willem Goossens"
date: "2025-11-13"
output: html_document
---

# WARNING
This file works, but we ran it on the remote desktops so we had to change some code to optimise the saving procedure
See code below


# OLD VERSION
1 LOAD
Empty environment
```{r}
rm(list=ls())
```

Load packages
```{r}
library(tidyverse)
library(plantnet)
library(httr)
library(rvest)
library(jsonlite)
```

Load data
```{r}
pol <- read.csv("../Data/Observation/observation_org_bees.csv")
```


2 PREPARE
## 2.1 Data
Get data already identified
```{r}
result_list_done <- read_rds("../Results/observation_org_identification.RData")
permission_denied <- read_csv( "../Extra/Intermediate/Permission_denied.csv")
already_identified <- names(result_list_done)
already_identified <- c(already_identified, permission_denied$denied)
```

Prepare data for identification
```{r}
# key
api_key <- "2b10bu236VtELMT8bV13UQb73e"

# Set the API endpoint
url_api <- paste0("https://my-api.plantnet.org/v2/identify/all?api-key=", api_key)
```


Get all observation data
```{r}
# only get picture data
obs <- pol[pol$has.photos,]

# get pictures per id
id_pol_all <- unique(obs$id)
```

## 2.2 Functions
```{r}
# based on function of PlantNet
# I just do not want to print the URL every time
buildURL <- function(key, imageURL, organs = 'auto', 
                     lang = 'en', no_reject = 'false'){
  
  # get URL 
  URLencoded <- sapply(imageURL, FUN = URLencode, reserved = TRUE, repeated = TRUE)
  
  # make URL
  url_string <- paste0("https://my-api.plantnet.org/v2/identify/all?",
                       "images=", paste(URLencoded, collapse = "&images="),
                       "&organs=", paste(organs, collapse = "&organs="),
                       "&no-reject=", no_reject,
                       "&lang=", lang,
                       "&api-key=", key)
}  
```


3 PLANTNET
## 3.1 Run function
```{r}
  # run for subset
  id_pol <- id_pol_all[!id_pol_all %in% already_identified]
  id_pol <- id_pol_all[1:10]
  id <- id_pol[1]
  # get data list
  results_list <- list()
  number_of_observations <- 0
  id = 40019426
  for(id in id_pol){
    # get URL
    imageURL <- obs$link[obs$id == id]
    imageURL <- imageURL[!duplicated(imageURL)]
    
    # read page
    page <- read_html(imageURL)
   
    # retrieve all images
    imgs <- html_elements(page, "img")
    
    # observation.org stores them in two formats
    # we retrieve both options
    src  <- html_attr(imgs, "src")
    datasrc <- html_attr(imgs, "data-src")
    
    # combine
    image_urls <- c(src, datasrc)
    
    # remove empty or NA
    image_urls <- image_urls[!is.na(image_urls) & image_urls != ""]
    
    # keep only real observation photos
    image_urls <- grep("/media/photo/.*\\.(jpg|jpeg)", image_urls, value = TRUE)
    # take them all as large pictures
    image_urls <- sub("\\?.*$", "", image_urls)
    # now remove duplicates
    image_urls <- image_urls[!duplicated(image_urls)]
    
    # Make relative URLs absolute
    # Extract the domain from the observation page URL
    domain <- sub("^https?://([^/]+).*", "\\1", imageURL)
  
    # Construct base URL (https + domain)
    base <- paste0("https://", domain)
  
    # Make relative URLs absolute using the correct domain
    image_urls <- ifelse(
      startsWith(image_urls, "http"),
      image_urls,
      paste0(base, image_urls))
    
    if(length(image_urls)<1){
      denied_id <- as.data.frame(id)
      colnames(denied_id) <- "denied"
      permission_denied <- bind_rows(permission_denied, denied_id)
    }
    
    if(length(image_urls)<1) next
  
    
    # create dataset to assign results
    results_pol <- data.frame(ID = numeric(), Score = numeric(), Name = character(),
                                   Common_name = character(), Name_author= character(),
                                   Genus= character(), Genus_author= character(), 
                                   Family = character(), Family_author = character(), 
                                   GBIF_ID = character(),POWO_ID = character(), 
                                   IUCN_ID = character(), IUCN = character())
    
    # create dataset to assign flower organs
    results_pol_organs <- data.frame(ID= numeric(), Organ = character(), Score = numeric(), 
                                     imageURL= character() )
    
    # Split into chunks of 5 images each (PlantNet limit)
    chunks <- ceiling(length(image_urls)/5)
    
    # make sure that we are able to run as manny observations as deemed necessary
    number_of_observations <- number_of_observations + chunks
  
    for (chunk in 1: chunks) {
        
      # get chunks
      length_chunks <- ceiling(length(image_urls)/chunks) 
      
      # create begin and end values for the plot observation ID
      min_chunk<- ((chunk-1)*length_chunks+1)
      max_chunk<- (chunk*length_chunks)
      if(max_chunk>length(image_urls)){
          max_chunk <- length(image_urls)
      }
          
      picturesURL <- image_urls[min_chunk: max_chunk]
        
      # Assign URL
      URL <- buildURL(key = api_key, imageURL = picturesURL, organs = rep("auto", length(picturesURL)), 
                      lang = "en", no_reject = 'true')
      
      # Run PlantNet
      response <- httr::GET(URL)
      
      # Check the status
      status <- response$status_code
    
      if (status == 200) {
          
           # get result from response and make it a table
           result <- content(response, as = "text", encoding = "UTF-8")
            
           # make data frame
           parsed_result <- fromJSON(result, flatten = TRUE)
            
           # get organ predicted
           predicted_organ <- parsed_result$predictedOrgans[,2:3]
           predicted_organ <- cbind(as.numeric(rep(id, nrow(parsed_result$predictedOrgans))), predicted_organ)
           colnames(predicted_organ) <- c("ID","Organ","Score")
           predicted_organ$imageURL <- as.character(picturesURL)
        
           # get plants predicted and change names
           predicted_plant <- cbind(rep(id, nrow(parsed_result$results)), parsed_result$results)
           if(ncol(predicted_plant)>14){
                predicted_plant <- predicted_plant[, c(1,2,3,5,6,7,9,10,12,13,14,15,16)]
                colnames(predicted_plant) <- c("ID","Score","Name","Common_name","Name_author","Genus","Genus_author","Family","Family_author",
                                               "GBIF_ID","POWO_ID","IUCN_ID","IUCN")
           } else if(ncol(predicted_plant) == 14) {
                predicted_plant <- predicted_plant[, c(1,2,3,5,6,7,9,10,12,13,14)]
                colnames(predicted_plant) <- c("ID","Score","Name","Common_name","Name_author","Genus","Genus_author","Family","Family_author",
                                               "GBIF_ID","POWO_ID")
           } else {
                predicted_plant <- predicted_plant[, c(1,2,3,5,6,7,9,10,12,13)]
                colnames(predicted_plant) <- c("ID","Score","Name","Common_name","Name_author","Genus","Genus_author","Family","Family_author",
                                               "GBIF_ID")
            }
            
           # only save the first common name given
           for(com_id in 1: nrow(parsed_result$results)){
             predicted_plant$Common_name[[com_id]] <- as.character(predicted_plant$Common_name[[com_id]][1])}
            
           # make this again a predictor
           predicted_plant$Common_name <- as.character(predicted_plant$Common_name)
           predicted_plant$ID <- as.numeric(predicted_plant$ID)
                  
            
           # Store results in a list (create a data frame for this image)
           results_pol <- bind_rows(results_pol, predicted_plant)
           results_pol_organs <- bind_rows(results_pol_organs, predicted_organ)
          
           } else {
           # create empty dataframe
           # only assign id
           add <- data.frame(ID= as.numeric(as.character((id))), Score = as.numeric(NA), Name = NA, Common_name = NA, Name_author= NA,
                                      Genus= NA, Genus_author= NA, Family = NA, Family_author = NA, 
                                      GBIF_ID = NA, POWO_ID = NA, IUCN_ID = NA, IUCN = NA)
            
           # add to results
           results_pol <- bind_rows(results_pol, add)
            
           # do the same for the organs
           add_organs <- data.frame(ID= as.numeric(as.character((id))),  Organ = NA, Score = NA)
           results_pol_organs <- bind_rows(results_pol_organs, add_organs)
          }
    }
    # create overall results as list
    results_list[[as.character(id)]] <- list(predicted_organ = results_pol_organs, predicted_plant = results_pol)
    
    if(number_of_observations >= 12) {
        break
    }
  }
  
  # paste this to the existing list of data
  results_list <- c(result_list_done, results_list)
  
  permission_denied <- as.data.frame(permission_denied)
  colnames(permission_denied) <- "denied"
  write_csv(permission_denied, "../Extra/Intermediate/Permission_denied.csv")
  
  # save together
  write_rds(results_list, "../Results/observation_org_identification.RData")
```




Retrieve all with highest scores
```{r}
# Load data again
results_list <-read_rds("../Results/observation_org_identification.RData")

# create empty data frame to paste most likely results in
pol_plantnet <- data.frame(ID = numeric(), Score = numeric(), Name = character(), Common_name = character(),
                           Name_author= character(),Genus= character(), Genus_author= character(), 
                           Family = character(), Family_author = character(), GBIF_ID = character(),
                           POWO_ID = character(), IUCN_ID = character(), IUCN = character(), 
                           Organ = character(), Genus_most= character(), URL = character())

# get observation data again
id_pol <- as.numeric(names(results_list))
id <- id_pol[2]
# create final dataset from the list 
for(id in id_pol){
  
  # predicted data for that observation ID
  predicted <-   results_list[[as.character(id)]]
  
  # first check for identifications which lack an organ, they are likely incorrect
  if(all(is.na(predicted$predicted_organ$Organ))){
    
    # create empty data frame to add
    add <- data.frame(ID= as.numeric(as.character((id))), Score = as.numeric(NA), Name = NA, 
                      Common_name = NA, Name_author= NA,
                      Genus= NA, Genus_author= NA,Family = NA, Family_author = NA, 
                      GBIF_ID = NA, POWO_ID = NA, IUCN_ID = NA, IUCN = NA, Genus_most = NA, Organ = "None", 
                      URL= obs$link[obs$id == id])
    
    # add to dataframe
    pol_plantnet <- bind_rows(pol_plantnet, add)
    
    # check whether any of the observations is a flower
    # if so, we will use the highest score 
    # this can be from another plant organ but that does not really matter here
  } else if(any(predicted$predicted_organ$Organ[!is.na(predicted$predicted_organ$Organ)] == "flower")){
    
    # add maximum scoring to pollination
    pol_plantnet <- bind_rows(pol_plantnet, 
                              c(predicted$predicted_plant[which.max(predicted$predicted_plant$Score),],
                                Organ ="flower", Genus_most = NA, URL= ( obs$link[obs$id == id])))
    
    
    # check for different genera
    genera <- names(sort(table(predicted$predicted_plant$Genus[predicted$predicted_plant$Score > 0.3]))[1])
    # check whether there are some observations for which there are more observations
    if(sort(table(predicted$predicted_plant$Genus))[1] >1){
      genus_plantnet_sp <- predicted$predicted_plant$Genus[which.max(predicted$predicted_plant$Score)]
      if(genus_plantnet_sp != genera){
        pol_plantnet$Genus_most[pol_plantnet$ID %in% id] <- genus_plantnet_sp
      }
    }
    
    
    # these are all the other identfications
    # for these we will use the highest identification number
  } else {
    # check the organ for which we obtained the highest observation identification
    organ_identified <- predicted$predicted_organ[which.max(predicted_organ$Score),]
    pol_plantnet <- bind_rows(pol_plantnet,
                              c(predicted$predicted_plant[which.max(predicted$predicted_plant$Score),],
                                Organ = organ_identified$Organ, Genus_most = NA,
                                URL=  obs$link[obs$id == id]))
    # check for different genera
    genera <- names(sort(table(predicted$predicted_plant$Genus[predicted$predicted_plant$Score > 0.3]))[1])
    # check whether there are some observations for which there are more observations
    if(sort(table(predicted$predicted_plant$Genus))[1] >1){
      genus_plantnet_sp <- predicted$predicted_plant$Genus[which.max(predicted$predicted_plant$Score)]
      if(genus_plantnet_sp != genera){
        pol_plantnet$Genus_most[pol_plantnet$ID %in% id] <- genus_plantnet_sp
      }
    }
  }
}
```





# Observation Version
```{r}
setwd("I:/")
library(future)
library(future.apply)
library(rvest)
library(httr)
library(jsonlite)
library(dplyr)
library(readr)
library(purrr)

# Parallelism safe for Windows network-heavy tasks
options(future.checks.connection = FALSE)
future::plan(sequential)

# Paths for checkpointing
results_file <- "observation_org_identification.RData"
denied_file  <- "Permission_denied.csv"
batch_size   <- 500  # process 500 obs per batch to avoid overload

# API key
api_key <- "2b10bu236VtELMT8bV13UQb73e"

# Load your observation data
pol <- read_csv("observation_org_bees.csv")
obs <- pol[pol$`has photos`,]

# Load previous results if they exist
if (file.exists(results_file)) results_list <- readRDS(results_file) else results_list <- list()
if (file.exists(denied_file)) permission_denied <- read_csv(denied_file) else permission_denied <- data.frame(denied = character())

already_identified <- c(names(results_list), permission_denied$denied)
id_pol_all <- unique(obs$id)
id_pol <- setdiff(id_pol_all, already_identified)

buildURL <- function(key, imageURL, organs = 'auto', lang = 'en', no_reject = 'false'){
  URLencoded <- sapply(imageURL, FUN = URLencode, reserved = TRUE, repeated = TRUE)
  paste0(
    "https://my-api.plantnet.org/v2/identify/all?",
    "images=", paste(URLencoded, collapse = "&images="),
    "&organs=", paste(organs, collapse = "&organs="),
    "&no-reject=", no_reject,
    "&lang=", lang,
    "&api-key=", key
  )
}

process_one_id <- function(id, obs, api_key){

  imageURL <- obs$link[obs$id == id]
  imageURL <- unique(imageURL)
  
  # Read page
  page <- tryCatch({
    con <- url(imageURL, open = "rb")
    on.exit(close(con), add = TRUE)
    read_html(con)
  }, error = function(e) NULL)
  if (is.null(page)) return(list(id = id, denied = TRUE, result = NULL))
  
  imgs <- html_elements(page, "img")
  src <- html_attr(imgs, "src")
  datasrc <- html_attr(imgs, "data-src")
  image_urls <- c(src, datasrc)
  image_urls <- image_urls[!is.na(image_urls) & image_urls != ""]
  image_urls <- grep("/media/photo/.*\\.(jpg|jpeg)", image_urls, value = TRUE)
  image_urls <- sub("\\?.*$", "", image_urls)
  image_urls <- unique(image_urls)
  
  domain <- sub("^https?://([^/]+).*", "\\1", imageURL)
  base <- paste0("https://", domain)
  image_urls <- ifelse(startsWith(image_urls, "http"), image_urls, paste0(base, image_urls))
  
  if (length(image_urls) < 1) return(list(id = id, denied = TRUE, result = NULL))
  
  results_pol <- list()
  results_pol_organs <- list()
  
  chunks <- ceiling(length(image_urls)/5)
  
  for (chunk in seq_len(chunks)) {
    length_chunks <- ceiling(length(image_urls)/chunks)
    min_chunk <- (chunk-1)*length_chunks + 1
    max_chunk <- min(chunk*length_chunks, length(image_urls))
    picturesURL <- image_urls[min_chunk:max_chunk]
    
    URL <- buildURL(api_key, picturesURL, organs = rep("auto", length(picturesURL)), lang = "en", no_reject = "true")
    
    response <- tryCatch(httr::GET(URL), error = function(e) NULL)
    if (is.null(response) || response$status_code != 200) next
    
    parsed_result <- fromJSON(content(response, "text"), flatten = TRUE)
    
    predicted_organ <- parsed_result$predictedOrgans[,2:3]
    predicted_organ <- cbind(ID = id, predicted_organ, imageURL = picturesURL)
    predicted_plant <- cbind(ID = id, parsed_result$results)
    
    results_pol[[length(results_pol) + 1]] <- predicted_plant
    results_pol_organs[[length(results_pol_organs) + 1]] <- predicted_organ
    
    Sys.sleep(0.2)  # small delay to reduce throttling
  }
  
  if (length(results_pol) == 0 && length(results_pol_organs) == 0) return(list(id = id, denied = TRUE, result = NULL))
  
  results_pol <- bind_rows(results_pol)
  results_pol_organs <- bind_rows(results_pol_organs)
  
  list(id = id, denied = FALSE, result = list(predicted_plant = results_pol, predicted_organ = results_pol_organs))
}

total_ids <- length(id_pol)
batches <- split(id_pol, ceiling(seq_along(id_pol)/batch_size))
batches <- batches[1:100]

begin <- Sys.time()

for (b in seq_along(batches)) {
  batch_ids <- batches[[b]]
  message("Processing batch ", b, " of ", length(batches), " (", length(batch_ids), " observations) at ", Sys.time())
  
  batch_results <- lapply(batch_ids, process_one_id, obs=obs, api_key=api_key)
  
  # Update results
  for (res in batch_results) {
    if (res$denied) {
      permission_denied <- bind_rows(permission_denied, data.frame(denied = res$id))
    } else {
      results_list[[as.character(res$id)]] <- res$result
    }
  }
  
  # Checkpoint after every batch
  saveRDS(results_list, results_file)
  write_csv(permission_denied, denied_file)
  
  closeAllConnections()
  gc()
  Sys.sleep(2)
}
end <- Sys.time()
end-begin
```


# iNaturalist Version
```{r}
library(rvest)
library(httr)
library(jsonlite)
library(dplyr)
library(readr)
library(purrr)


# Paths for checkpointing
results_file <- "iNaturalist_identification.RData"
denied_file  <- "Permission_denied_iNat.csv"
batch_size   <- 500  # process 500 obs per batch to avoid overload

# API key
api_key <- "2b10bu236VtELMT8bV13UQb73e"

# Load your observation data
obs <- read_csv("../Data/Observation/iNaturalist_bees.csv", show_col_types = FALSE)
photos <- read_csv("../Data/Observation/iNaturalist_photos.csv", show_col_types = FALSE)

# Load previous results if they exist
if (file.exists(results_file)) results_list <- readRDS(results_file) else results_list <- list()
if (file.exists(denied_file)) permission_denied <- read_csv(denied_file) else permission_denied <- data.frame(denied = numeric())

already_identified <- c(names(results_list), permission_denied$denied)
id_pol_all <- unique(obs$observation_uuid)
id_pol <- setdiff(id_pol_all, already_identified)

buildURL <- function(key, imageURL, organs = 'auto', lang = 'en', no_reject = 'true'){
  URLencoded <- sapply(imageURL, FUN = URLencode, reserved = TRUE, repeated = TRUE)
  paste0(
    "https://my-api.plantnet.org/v2/identify/all?",
    "images=", paste(URLencoded, collapse = "&images="),
    "&organs=", paste(organs, collapse = "&organs="),
    "&no-reject=", no_reject,
    "&lang=", lang,
    "&api-key=", key
  )
}

# test id
id <- photos$observation_uuid[1]

process_one_id_inat <- function(id, photos, api_key){

  imageURL <- photos$photo_id[photos$observation_uuid == id]
  imageURL <- unique(imageURL)
  image_type <- photos$extension[photos$observation_uuid == id]
  image_urls <- paste("https://inaturalist-open-data.s3.amazonaws.com/photos/", imageURL, "/original.", image_type, sep="")
  
  if (length(image_urls) < 1) return(list(id = id, denied = TRUE, result = NULL))
  
  results_pol <- list()
  results_pol_organs <- list()
  
  chunks <- ceiling(length(image_urls)/5)

    for (chunk in seq_len(chunks)) {
    length_chunks <- ceiling(length(image_urls)/chunks)
    min_chunk <- (chunk-1)*length_chunks + 1
    max_chunk <- min(chunk*length_chunks, length(image_urls))
    picturesURL <- image_urls[min_chunk:max_chunk]
    
    URL <- buildURL(api_key, picturesURL, organs = rep("auto", length(picturesURL)), lang = "en", no_reject = "true")
    
    response <- tryCatch(httr::GET(URL), error = function(e) NULL)

    if (is.null(response) || response$status_code != 200) next
    
    parsed_result <- fromJSON(content(response, "text"), flatten = TRUE)
    
    predicted_organ <- parsed_result$predictedOrgans[,2:3]
    predicted_organ <- cbind(ID = id, predicted_organ, imageURL = picturesURL)
    predicted_plant <- cbind(ID = id, parsed_result$results)
    
    results_pol[[length(results_pol) + 1]] <- predicted_plant
    results_pol_organs[[length(results_pol_organs) + 1]] <- predicted_organ
    
    Sys.sleep(0.2)  # small delay to reduce throttling
  }
  
  if (length(results_pol) == 0 && length(results_pol_organs) == 0) return(list(id = id, denied = TRUE, result = NULL))
  
  results_pol <- bind_rows(results_pol)
  results_pol_organs <- bind_rows(results_pol_organs)
  
  list(id = id, denied = FALSE, result = list(predicted_plant = results_pol, predicted_organ = results_pol_organs))
}

total_ids <- length(id_pol)
batches <- split(id_pol, ceiling(seq_along(id_pol)/batch_size))
batches <- batches[1]

begin <- Sys.time()

for (b in seq_along(batches)) {
  batch_ids <- batches[[b]]
  message("Processing batch ", b, " of ", length(batches), " (", length(batch_ids), " observations) at ", Sys.time())
  
  batch_results <- lapply(batch_ids, process_one_id_inat, photos=photos, api_key=api_key)
  
  # Update results
  for (res in batch_results) {
    if (res$denied) {
      permission_denied <- bind_rows(permission_denied, data.frame(denied = res$id))
    } else {
      results_list[[as.character(res$id)]] <- res$result
    }
  }
  
  # Checkpoint after every batch
  saveRDS(results_list, results_file)
  write_csv(permission_denied, denied_file)
  
  gc()
  Sys.sleep(2)
}
end <- Sys.time()
end-begin
```